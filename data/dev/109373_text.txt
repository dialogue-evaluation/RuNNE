Искусственный интеллект Google DeepMind научился читать по губам лучше человека
Логотип DeepMind
Алгоритмы искусственного интеллекта, разработанные командой Google DeepMind в сотрудничестве с учёными Оксфордского университета, превзошли человека в умении понимать речь наблюдением артикуляции говорящего.

У созданной ими программы результаты оказались на 35 % лучше, чем у профессионального «считывателя» по губам.

ИИ-систему Google обучили на шести телешоу (таких как Newsnight, BBC Breakfast и Question Time), которые выходили в эфир с 2010 по 2015 года, «скормив» ей видео общей продолжительностью 5 тысяч часов (около 118 тысяч предложений). Эффективность алгоритмов проверялась на новых выпусках телепрограмм, транслировавшихся с марта по сентябрь 2016 года.

Из случайной выборки 200 видеофрагментов человек, профессиональный чтец по губам, безошибочно распознал только 12,4 % произнесённых слов, в то время как компьютерные алгоритмы — 46,8 %. При этом полученные результаты могли быть ещё лучше, однако в некоторых случаях аудио и видео отставали почти на секунду, что мешало ИИ правильно выстраивать ассоциативные связи.

Ранее система глубинного, или глубокого обучения (алгоритмы, которые учат нейросети «думать» и выстраивать логические цепочки), разработанная исследователями из Оксфорда, также превзошла человека на тесте GRID. Но если словарный запас GRID состоял из всего лишь 51 уникального слова, то в ТВ-шоу BBC таковых было произнесено , что представляло гораздо более трудную задачу для компьютерных алгоритмов.

ИИ-систему Google вряд ли можно будет задействовать для прослушки, т. к. микрофоны направленного действия справляются с этой задачей намного лучше. Более вероятный сценарий — применение алгоритмов в потребительских устройствах, чтобы помочь Android-смартфонам понять, что им пытается сказать пользователь в шумной обстановке.
